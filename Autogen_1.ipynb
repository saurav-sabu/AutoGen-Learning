{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sqvzC9hyyaJ",
        "outputId": "0b0a2a21-5c86-4731-b0e8-e6d156599b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/97.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.4/306.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q autogen-agentchat pydantic asyncio autogen-ext[openai]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY"
      ],
      "metadata": {
        "id": "YnwCGoCA3F11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Access the LLM"
      ],
      "metadata": {
        "id": "l4v48vg76Fo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_core.models import UserMessage\n",
        "import asyncio\n",
        "\n",
        "model_client = OpenAIChatCompletionClient(\n",
        "    model=\"gemini-2.0-flash\"\n",
        ")\n",
        "\n",
        "result = await model_client.create([UserMessage(content=\"What is capital of India\",source=\"user\")])\n",
        "print(result)\n",
        "await model_client.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKFxcMOczSuc",
        "outputId": "bdf5c8b9-f5ae-4c24-eead-3063d52bf8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish_reason='stop' content='The capital of India is **New Delhi**.\\n' usage=RequestUsage(prompt_tokens=5, completion_tokens=10) cached=False logprobs=None thought=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_client = OpenAIChatCompletionClient(\n",
        "    model=\"gemini-2.0-flash\"\n",
        ")\n",
        "\n",
        "result = await model_client.create([UserMessage(content=\"What is Large Language Model\",source=\"user\")])\n",
        "print(result)\n",
        "await model_client.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZWDt9eL3NsZ",
        "outputId": "c987f815-7a67-4366-d7a9-d0c1574aee01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish_reason='stop' content='A Large Language Model (LLM) is a type of artificial intelligence (AI) model designed to understand and generate human language. They are \"large\" because they are trained on massive amounts of text data, often billions of words, and contain a vast number of parameters (the variables the model uses to learn). This scale allows them to perform a wide range of language-related tasks with impressive fluency and coherence.\\n\\nHere\\'s a breakdown of the key aspects:\\n\\n**Key Characteristics:**\\n\\n*   **Trained on Massive Datasets:** LLMs learn from enormous amounts of text data scraped from the internet, including books, articles, websites, code, and more. This exposure allows them to learn patterns in language, relationships between words, grammar, and even different writing styles.\\n*   **Deep Learning Architecture:** They typically use deep learning architectures, most commonly the Transformer architecture. This architecture is particularly effective at capturing long-range dependencies in text, meaning it can understand the context of words even when they are far apart in a sentence or paragraph.\\n*   **Generative Capabilities:** LLMs aren\\'t just about understanding language; they are also capable of generating it. They can create new text that is coherent, grammatically correct, and relevant to a given prompt or context.\\n*   **Parameter Size:** The \"large\" in LLM refers to the number of parameters. These parameters are the adjustable variables within the model that are tuned during training.  More parameters generally allow the model to capture more complex patterns in the data, leading to better performance.  Modern LLMs can have billions or even trillions of parameters.\\n\\n**How They Work (Simplified):**\\n\\n1.  **Training:** The model is fed massive amounts of text. During this process, the model adjusts its internal parameters to predict the next word in a sequence.  It learns by trial and error, constantly refining its predictions based on the actual words that follow.\\n\\n2.  **Inference (Using the Model):** When you give the model a prompt (e.g., \"Write a poem about a cat\"), it uses the patterns and relationships it learned during training to predict the most likely sequence of words that would follow.  It generates the text word by word, based on the context of the prompt and its learned knowledge.\\n\\n**Capabilities of LLMs:**\\n\\nLLMs are capable of a wide array of tasks, including:\\n\\n*   **Text Generation:**  Writing articles, poems, stories, scripts, code, and other creative content.\\n*   **Translation:** Translating text between different languages.\\n*   **Summarization:** Condensing long pieces of text into shorter summaries.\\n*   **Question Answering:** Answering questions based on information they have learned or are provided in context.\\n*   **Sentiment Analysis:** Determining the emotional tone of a piece of text.\\n*   **Code Generation:** Writing code in various programming languages.\\n*   **Chatbots and Conversational AI:** Powering chatbots that can engage in natural-sounding conversations.\\n*   **Content Creation:** Assisting in the creation of various forms of digital content.\\n*   **Data Analysis:**  Extracting and summarizing insights from textual data.\\n\\n**Examples of LLMs:**\\n\\n*   **GPT (Generative Pre-trained Transformer) series (e.g., GPT-3, GPT-4) - Developed by OpenAI.**\\n*   **BERT (Bidirectional Encoder Representations from Transformers) - Developed by Google.**\\n*   **LaMDA (Language Model for Dialogue Applications) - Developed by Google.**\\n*   **LLaMA (Large Language Model Meta AI) - Developed by Meta (Facebook).**\\n*   **PaLM (Pathways Language Model) - Developed by Google.**\\n\\n**Limitations and Challenges:**\\n\\nWhile LLMs are powerful, they also have limitations:\\n\\n*   **Bias:** They can perpetuate and amplify biases present in the data they were trained on, leading to unfair or discriminatory outputs.\\n*   **Hallucination:** They can sometimes generate inaccurate or nonsensical information that sounds plausible (often referred to as \"hallucinations\").\\n*   **Lack of Real-World Understanding:** They operate based on patterns in text and don\\'t have genuine understanding of the real world or human emotions.\\n*   **Computational Cost:** Training and running LLMs require significant computational resources and energy.\\n*   **Ethical Concerns:** Concerns about misuse for spreading misinformation, creating deepfakes, and automating jobs.\\n*   **Explainability:** It can be difficult to understand why an LLM generates a particular output, making it hard to debug and control their behavior.\\n\\n**In Summary:**\\n\\nLLMs are a groundbreaking technology that has transformed the landscape of AI and natural language processing. They are powerful tools with the potential to revolutionize how we interact with computers and information. However, it\\'s crucial to be aware of their limitations and ethical implications to ensure they are used responsibly and for the benefit of society.\\n' usage=RequestUsage(prompt_tokens=5, completion_tokens=1026) cached=False logprobs=None thought=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AgentChat"
      ],
      "metadata": {
        "id": "RshnUkq46DEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 1:"
      ],
      "metadata": {
        "id": "ypFgXlHc7Q2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient"
      ],
      "metadata": {
        "id": "HC0hZHT35k7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_client = OpenAIChatCompletionClient(\n",
        "    model=\"gemini-2.0-flash\"\n",
        ")\n",
        "\n",
        "my_first_agent = AssistantAgent(name=\"My_First_Agent\",model_client=model_client)\n",
        "my_first_agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sy7ocMO3Y2f",
        "outputId": "e7f16f02-aece-4307-c406-2463a84cb14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autogen_agentchat.agents._assistant_agent.AssistantAgent at 0x7d443d7972d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await my_first_agent.run(task=\"What is LLM\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JpYlvox4u5V",
        "outputId": "919ea4a2-3e0f-413f-cf99-5fe873bd06f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 6, 23, 17, 47, 42, 59823, tzinfo=datetime.timezone.utc), content='What is LLM', type='TextMessage'), TextMessage(source='My_First_Agent', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=339), metadata={}, created_at=datetime.datetime(2025, 6, 23, 17, 47, 44, 865950, tzinfo=datetime.timezone.utc), content='LLM stands for Large Language Model. These are AI models that are trained on massive datasets of text and code to understand and generate human-like text. They can perform a wide range of tasks, including:\\n\\n*   **Text generation:** Writing articles, stories, poems, code, and other creative content.\\n*   **Text summarization:** Condensing long documents into shorter, more concise summaries.\\n*   **Translation:** Translating text from one language to another.\\n*   **Question answering:** Answering questions based on the information they have been trained on.\\n*   **Chatbots:** Engaging in conversations with users and providing information or assistance.\\n*   **Code generation:** Writing code in various programming languages.\\n*   **Sentiment analysis:** Determining the emotional tone of a piece of text.\\n\\nThe \"large\" in Large Language Model refers to the massive number of parameters (weights and biases) that these models have. These parameters are adjusted during training to enable the model to learn complex patterns and relationships in the data. The more parameters a model has, the more complex patterns it can learn, and the better it can perform on a variety of tasks.\\n\\nExamples of well-known LLMs include:\\n\\n*   **GPT models (GPT-3, GPT-4) by OpenAI:** Known for their strong text generation capabilities.\\n*   **LaMDA and Gemini by Google:** Used in chatbots and other applications.\\n*   **LLaMA by Meta:** An open-source model intended for research and development.\\n\\nLLMs are a rapidly evolving field, and new models with improved capabilities are constantly being developed.\\n\\nTERMINATE\\n', type='TextMessage')] stop_reason=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.messages[-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Koc8xt5yP8",
        "outputId": "9e73e7cb-24de-4bf0-baa9-cf41281d43e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM stands for Large Language Model. These are AI models that are trained on massive datasets of text and code to understand and generate human-like text. They can perform a wide range of tasks, including:\n",
            "\n",
            "*   **Text generation:** Writing articles, stories, poems, code, and other creative content.\n",
            "*   **Text summarization:** Condensing long documents into shorter, more concise summaries.\n",
            "*   **Translation:** Translating text from one language to another.\n",
            "*   **Question answering:** Answering questions based on the information they have been trained on.\n",
            "*   **Chatbots:** Engaging in conversations with users and providing information or assistance.\n",
            "*   **Code generation:** Writing code in various programming languages.\n",
            "*   **Sentiment analysis:** Determining the emotional tone of a piece of text.\n",
            "\n",
            "The \"large\" in Large Language Model refers to the massive number of parameters (weights and biases) that these models have. These parameters are adjusted during training to enable the model to learn complex patterns and relationships in the data. The more parameters a model has, the more complex patterns it can learn, and the better it can perform on a variety of tasks.\n",
            "\n",
            "Examples of well-known LLMs include:\n",
            "\n",
            "*   **GPT models (GPT-3, GPT-4) by OpenAI:** Known for their strong text generation capabilities.\n",
            "*   **LaMDA and Gemini by Google:** Used in chatbots and other applications.\n",
            "*   **LLaMA by Meta:** An open-source model intended for research and development.\n",
            "\n",
            "LLMs are a rapidly evolving field, and new models with improved capabilities are constantly being developed.\n",
            "\n",
            "TERMINATE\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 2:"
      ],
      "metadata": {
        "id": "pFpsPtmu7UCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_client = OpenAIChatCompletionClient(\n",
        "    model=\"gemini-2.0-flash\"\n",
        ")\n",
        "\n",
        "my_first_agent = AssistantAgent(name=\"My_First_Agent\",model_client=model_client,system_message=\"Give me output in JSON\")\n",
        "\n",
        "result = await my_first_agent.run(task=\"What is LLM\")\n",
        "print(result.messages[-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlta2I6P54zs",
        "outputId": "2a6adeb4-0e89-4f80-efd6-52bffc21334b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"term\": \"LLM\",\n",
            "  \"definition\": \"LLM stands for Large Language Model. It is a type of artificial intelligence (AI) model, specifically a deep learning model, that is trained on a massive dataset of text and code. This training allows the model to understand and generate human-like text in response to a wide range of prompts and questions. LLMs are used for various natural language processing (NLP) tasks, including text generation, translation, summarization, question answering, and more.\",\n",
            "  \"key_characteristics\": [\n",
            "    \"Large-scale training: Trained on massive datasets, often consisting of billions or trillions of words.\",\n",
            "    \"Deep learning architecture: Typically based on transformer neural networks.\",\n",
            "    \"Text generation: Capable of generating coherent and contextually relevant text.\",\n",
            "    \"Natural language understanding: Can understand and interpret human language.\",\n",
            "    \"Versatility: Applicable to a wide range of NLP tasks.\"\n",
            "  ],\n",
            "  \"examples\": [\n",
            "    \"GPT-3\",\n",
            "    \"GPT-4\",\n",
            "    \"LaMDA\",\n",
            "    \"BERT\",\n",
            "    \"PaLM\"\n",
            "  ],\n",
            "  \"applications\": [\n",
            "    \"Chatbots\",\n",
            "    \"Virtual assistants\",\n",
            "    \"Content creation\",\n",
            "    \"Code generation\",\n",
            "    \"Machine translation\",\n",
            "    \"Text summarization\",\n",
            "    \"Question answering\"\n",
            "  ]\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXqDV09t7NXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}